
<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 3.0.0">
  <meta name="generator" content="Hugo 0.49.2" />
  <meta name="author" content="Chaire VISA DEEP">

  
  
  
  
    
  
  <meta name="description" content="Towards visual reasoning in deep learning">

  
  <link rel="alternate" hreflang="en-us" href="/">

  


  

  

  

  
  
  
  <meta name="theme-color" content="#e0491f">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css" integrity="sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  <link rel="stylesheet" href="/styles.css">
  
  <link rel="stylesheet" href="/css/search_bar.css">
  

  
  
  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="VISA DEEP">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="VISA DEEP">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@ramealexandre">
  <meta property="twitter:creator" content="@ramealexandre">
  
  <meta property="og:site_name" content="VISA DEEP">
  <meta property="og:url" content="/">
  <meta property="og:title" content="VISA DEEP">
  <meta property="og:description" content="Towards visual reasoning in deep learning">
  
  
    
  <meta property="og:image" content="/img/icon-192.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="og:updated_time" content="2016-04-20T00:00:00&#43;02:00">
  

  

  









<link rel="icon" type="image/png" href="/img/favicon32.png">
<link rel="apple-touch-icon" type="image/png" href="/img/favicon180.png">


  <title>VISA DEEP</title>

</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71" >

<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">VISA DEEP</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about" data-target="#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#people" data-target="#people">
            
            <span>People</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#publications" data-target="#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

      

        

        
      </ul>

    </div>
  </div>
</nav>



<span id="homepage" style="display: none"></span>


  





  
  
  
  <section id="about" class="home-section">
    <div class="container">
      



<div class="row" itemprop="author" itemscope itemtype="http://schema.org/Person"
  itemref="person-email person-telephone">
  <div class="col-xs-12 col-md-4">
    <div id="profile">

      
      <div class="portrait" style="background-image: url('/img/reasoning.jpg');">
      </div>
      <meta itemprop="image" content="/img/reasoning.jpg">
      

      <div class="portrait-title">
        <h2 itemprop="name">Chaire VISA DEEP</h2>
        <h3 itemprop="jobTitle">Towards visual reasoning in deep learning</h3>

        
        

        
      </div>

      <link itemprop="url" href="/">

      <ul class="network-icon" aria-hidden="true">
        
        
        
        
        <li>
          <a itemprop="sameAs" href="mailto:matthieu.cord@lip6.fr" target="_blank" rel="noopener">
            <i class="fa fa-envelope big-icon"></i>
          </a>
        </li>
        
        
        
        
        
        
        <li>
          <a itemprop="sameAs" href="https://github.com/chaire-visadeep" target="_blank" rel="noopener">
            <i class="fab fa-github big-icon"></i>
          </a>
        </li>
        
      </ul>

    </div>
  </div>
  <div class="col-xs-12 col-md-8" itemprop="description">

    <p>This project is supervised by Pr M. Cord from LIP6 and was selected under in the call launched in July 2019 by the National Research Agency (ANR) for the creation of research and teaching chairs in AI.</p>

<p>Our main objective is to tackle complex vision-driven recognition and understanding tasks.
We propose to investigate tasks of visual reasoning beyond merely large scale image classification. It is required to decline some reasoning processes in the visual analysis scheme. We intend to explore the combination of elementary reasoning blocks into deep architectures. We want to question the type of blocks, structures and rules (if any) we can include. The main requirement in terms of types of structures we consider is to get a final hybrid (Explicit/Implicit) architecture that is end-to-end trainable. We already experimented in several contexts how performance increases using fully trainable architectures. Getting a differentiable function for the final DNN greatly constraints the type of combination or the nature of reasoning. We will consider different contexts including the VQA task to experiment our propositions. We also want to measure or visualize how the information is processed inside the deep nets. It is a key to our deep reasoning models being tooled up of explanation capacities. In particular, we will investigate different visualizing processes in the context of autonomous driving where building machines explaining their decisions is of critical importance.</p>


    <div class="row">


      

     

    </div>
  </div>
</div>

    </div>
  </section>
  

  
  
  
  <section id="people" class="home-section">
    <div class="container">
      









<div class="row justify-content-center people-widget">
  

  

  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">Primary Investigator</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="http://webia.lip6.fr/~cord/"><img class="avatar avatar-circle" src="/authors/cord/avatar_hu8843c3e6e5af441d785968d1167e6b5d_31196_270x270_fill_box_center_2.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="http://webia.lip6.fr/~cord/">Matthieu Cord</a></h2>
      <h3>LIP6, Sorbonne Université</h3>
      <h3>Professor</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">PhD Students</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="https://alexrame.github.io/"><img class="avatar avatar-circle" src="/authors/rame/avatar_hu58d8d21f671b4cb2c89e0a6b9efb7c6c_68885_270x270_fill_q75_box_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="https://alexrame.github.io/">Alexandre Ramé</a></h2>
      <h3>LIP6, Sorbonne Université</h3>
      <h3>Thesis subject: deep ensembles to boost image understanding</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="https://cdancette.fr"><img class="avatar avatar-circle" src="/authors/cdancette/avatar_hu2a04796a2b2d68a530863031c0a8bc70_53664_270x270_fill_q75_box_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="https://cdancette.fr">Corentin Dancette</a></h2>
      <h3>LIP6, Sorbonne Université</h3>
      <h3>Thesis subject: deep learning for vision reasoning</h3>
      
      
    </div>
  </div>
  
  
</div>

    </div>
  </section>
  

  
  
  
  <section id="publications" class="home-section">
    <div class="container">
      




<div class="row">
  <div class="col-12 col-lg-4 section-heading">
    <h1>Publications</h1>
    
    
  </div>
  <div class="col-12 col-lg-8">
    

    
    
    

    

    
    
    <div class="media stream-item" itemscope itemtype="http://schema.org/Event">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0" itemprop="name">
      Fishr: Invariant Gradient Variances for Out-of-distribution Generalization
    </h3>

    <div class="stream-meta article-metadata">
      <div itemprop="author">
        Alexandre Ramé, Corentin Dancette, Matthieu Cord</div>
      arXiv Preprint<br>
      
    </div>

    <div class="ml-3">
      
      
      
      <img src="/publication/fishr/featured_hua120572edaf12c0874474a9b9cf1e6b5_52251_400x0_resize_box_2.png" itemprop="image">
      
    </div>

    
    
    
    
    
    <div class="article-style" itemprop="articleBody">
      We introduce and motivate a new regularization that enforces invariance in the domain-level gradient variances across the different training domains in order to improve out-of-distribution generalization.
    </div>
    

    <div class="talk-links">
      















<a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2109.02934" target="_blank"
  rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-primary btn-outline my-1 mr-1 btn-sm js-cite-modal"
  data-filename="/publication/fishr/cite.bib">
  Cite
</button>




<a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="https://github.com/alexrame/fishr" target="_blank"
  rel="noopener">
  Code
</a>












    </div><br />
  </div>
</div>

    
    <div class="media stream-item" itemscope itemtype="http://schema.org/Event">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0" itemprop="name">
      Beyond question-based biases: Assessing multimodal shortcut learning in visual question answering
    </h3>

    <div class="stream-meta article-metadata">
      <div itemprop="author">
        Corentin Dancette, Rémi Cadène, Damien Teney, Matthieu Cord</div>
      ICCV 2021<br>
      
    </div>

    <div class="ml-3">
      
      
      
      <img src="/publication/beyond/featured_huf4797df02cc98c05604cd88d0cd7d121_384475_400x0_resize_box_2.png" itemprop="image">
      
    </div>

    
    
    
    
    
    <div class="article-style" itemprop="articleBody">
      We propose an experimental protocol to evaluate model&rsquo;s reliance on multimodal biases.
    </div>
    

    <div class="talk-links">
      















<a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2104.03149.pdf" target="_blank"
  rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-primary btn-outline my-1 mr-1 btn-sm js-cite-modal"
  data-filename="/publication/beyond/cite.bib">
  Cite
</button>













    </div><br />
  </div>
</div>

    
    <div class="media stream-item" itemscope itemtype="http://schema.org/Event">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0" itemprop="name">
      MixMo: Mixing Multiple Inputs for Multiple Outputs via Deep Subnetworks
    </h3>

    <div class="stream-meta article-metadata">
      <div itemprop="author">
        Alexandre Ramé, Rémy Sun, Matthieu Cord</div>
      ICCV 2021<br>
      
    </div>

    <div class="ml-3">
      
      
      
      <img src="/publication/mixmo/featured_hu2e0d7a98a8814d8533dece18ae5f654d_110228_400x0_resize_q75_box.jpg" itemprop="image">
      
    </div>

    
    
    
    
    
    <div class="article-style" itemprop="articleBody">
      We introduce a new generalized framework for learning multi-input multi-output subnetworks and study how to best mix the inputs. We obtain sota on CIFAR and Tiny ImageNet by better leveraging the expressiveness of large networks.
    </div>
    

    <div class="talk-links">
      















<a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2103.06132" target="_blank"
  rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-primary btn-outline my-1 mr-1 btn-sm js-cite-modal"
  data-filename="/publication/mixmo/cite.bib">
  Cite
</button>




<a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="https://github.com/alexrame/mixmo-pytorch" target="_blank"
  rel="noopener">
  Code
</a>












    </div><br />
  </div>
</div>

    
    <div class="media stream-item" itemscope itemtype="http://schema.org/Event">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0" itemprop="name">
      DICE: Diversity in Deep Ensembles via Conditional Redundancy Adversarial Estimation
    </h3>

    <div class="stream-meta article-metadata">
      <div itemprop="author">
        Alexandre Ramé, Matthieu Cord</div>
      ICLR 2021<br>
      
    </div>

    <div class="ml-3">
      
      
      
      <img src="/publication/dice/featured_hucacb5a5b697f7d288db4d1257c796f1e_617503_400x0_resize_q75_box.jpg" itemprop="image">
      
    </div>

    
    
    
    
    
    <div class="article-style" itemprop="articleBody">
      Driven by arguments from information theory, we introduce a new learning strategy for deep ensembles that increases diversity among members: we adversarially prevent features from being conditionally redundant.
    </div>
    

    <div class="talk-links">
      















<a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2101.05544.pdf" target="_blank"
  rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-primary btn-outline my-1 mr-1 btn-sm js-cite-modal"
  data-filename="/publication/dice/cite.bib">
  Cite
</button>









<a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="https://drive.google.com/file/d/1Kcu4YZYn4yowp9H6CKht_upoI6-2plaU/view?usp=sharing" target="_blank"
  rel="noopener">
  Poster
</a>




<a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="https://drive.google.com/file/d/1YbQTExQAl4kTmEtaHCSK9WUtfiK7vnKS/view?usp=sharing" target="_blank"
  rel="noopener">
  Slides
</a>




<a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="https://iclr.cc/virtual/2021/poster/2650" target="_blank"
  rel="noopener">
  Video
</a>






<a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="https://openreview.net/forum?id=R2ZlTVPx0Gk" target="_blank"
  rel="noopener">
  OpenReview
</a>


    </div><br />
  </div>
</div>

    
    <div class="media stream-item" itemscope itemtype="http://schema.org/Event">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0" itemprop="name">
      RUBi: Reducing unimodal biases for Visual Question Answering
    </h3>

    <div class="stream-meta article-metadata">
      <div itemprop="author">
        Rémi Cadène, Corentin Dancette, Hedi Ben-Younes, Devi Parikh, Matthieu Cord</div>
      NeurIPS 2019<br>
      
    </div>

    <div class="ml-3">
      
      
      
      <img src="/publication/rubi/featured_hu3c27bfaba8b0c96d165673bd08cb907c_92990_400x0_resize_box_2.png" itemprop="image">
      
    </div>

    
    
    
    
    
    <div class="article-style" itemprop="articleBody">
      We introduce a strategy to reduce bias in models for Visual Question Answering.
    </div>
    

    <div class="talk-links">
      















<a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/1906.10169.pdf" target="_blank"
  rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-primary btn-outline my-1 mr-1 btn-sm js-cite-modal"
  data-filename="/publication/rubi/cite.bib">
  Cite
</button>













    </div><br />
  </div>
</div>

    

  </div>
</div>

    </div>
  </section>
  



<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    &copy; 2018 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>





<script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        CommonHTML: { linebreaks: { automatic: true } },
        tex2jax: { inlineMath: [ ['$', '$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\\[', '\\]'] ], processEscapes: false },
        TeX: { noUndefined: { attributes: { mathcolor: 'red', mathbackground: '#FFEEEE', mathsize: '90%' } } },
        messageStyle: 'none'
      });
    </script>





<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>





<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>




<script src="/js/hugo-academic.js"></script>














<script src="https://cdnjs.cloudflare.com/ajax/libs/instantsearch.js/2.10.2/instantsearch.min.js" integrity="sha256-gFCtPk/sonctyfwYOgjrPoWApQ0rqB6ezBBZ7p32yGc=" crossorigin="anonymous"></script>
<script>
  const content_type = {
    'post': "Posts",
  'project': { { i18n "projects" } },
  'publication' : { { i18n "publications" } },
  'talk' : { { i18n "talks" } }
      };

  function getTemplate(templateName) {
    return document.querySelector(`#${templateName}-template`).innerHTML;
  }

  const options = {
    appId: "",
  apiKey: { { .Site.Params.search.algolia.api_key } },
  indexName: { { .Site.Params.search.algolia.index_name } },
  routing: true,
    searchParameters: {
    hitsPerPage: 10
  },
  searchFunction: function(helper) {
    let searchResults = document.querySelector('#search-hits')
    if (helper.state.query === '') {
      searchResults.style.display = 'none';
      return;
    }
    helper.search();
    searchResults.style.display = 'block';
  }
      };

  const search = instantsearch(options);

  
  search.addWidget(
    instantsearch.widgets.searchBox({
      container: '#search-box',
      placeholder: "Search..."
        })
  );

  
  search.addWidget(
    instantsearch.widgets.infiniteHits({
      container: '#search-hits',
      templates: {
        empty: '<div class="search-no-results">' + "No results found" + '</div>',
      item: getTemplate('search-hit')
          },
      cssClasses: {
      showmoreButton: 'btn btn-primary btn-outline'
    }
        })
  );

  
  search.on('render', function () {
    $('.search-hit-type').each(function (index) {
      let content_key = $(this).text();
      if (content_key in content_type) {
        $(this).text(content_type[content_key]);
      }
    });
  });

  
  search.start();
</script>


</body>

</html>


